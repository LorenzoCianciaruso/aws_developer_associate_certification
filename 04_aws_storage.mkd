# 04. AWS Storage

* Block storage: Data are stored in chuncks called Blocks, these are associated to an instance. Low latency
* File storage: There is a file system and multiple users can access it
* Object storage: Flat address space addressed by a key


## S3

Fully manage object storage. Unlimited scalability and high availability, file stored across multiple AZs
Largest file is 5 terabytes

Durability: 99.999999999%
Availability: 99.99%

Bucket has to be named uniquely globally
By default 100 buckets limit but it can be increased

### Storage classes

* Frequently accessed
* Infrequently accessed: more cost effective than Standard-IA but it has less Availability 99.5%
* Intelligent Tiering: depending on how many time you access the data AWS will move objects to the infrequently accessed if they aren't used
much

### Security


* Bucket policy
* Access Control List: for users outside your AWS account.
* Data Encryption: via S3 managed keys, KMS manages keys, Customer Managed (Encryption Infographic)[https://awsinfographics.s3.amazonaws.com/S3_Encryption_Infographic.png]

**Features:**
* Versioning, once enabled it can be disabled but only suspended. It adds costs

**S3 anti-patterns:**
* Data archiving for long term use
* Data changing frequently
* File system requirements
* Structured data with queries

## Amazon Glacier

Half the cost than S3, but doesn't provide immediate access (cold storage)
Good for **backups** and archival requirements. Same Durability than S3, but it can take up to 7hrs to get data.
Everything is done via Apis, no portal.

You need to create a vault first and then upload your data to Glacier.

Data Retrieval: 
* Expedite limit to 250MB available in 1-5min.
* Standard: any size but 3-5 hours
* Bulk: Petabytes but up to 12 hrs

### Security
Data is encrypted, and you have Vault access policies and vault Lock Policies

## EC2 Instance Storage 
Block Storage Temporary storage, not recommended for critical data. They use the instance storage, and because of that if the instance is stopped or it has a hardware
fault, you'll lose the data. If reboted it's ok because the storage will be on the same host where it run previously.

**Why should you use it?** Because it's very fast, up to 3.3million IOPS in read and 1M IOPS in write, and it doesn't have any additional cost than just the EC2 instance itself. For data rapidling changing.

Not good for critical data, if multiple users need to access it 

## EBS
Block Storage
It's a persistent storage that you can apply to an EC2 instance. You can only associated an EBS storage to one EC2, but multiple EBS storages can be associated to one EC2 instance. One EBS storage can only be associated to an EC2 instance withing the same region, and if the machine fails it can be moved onto another machine using a snapshot for example.

You can take snapshot of an EBS, save the image in S3 and then recover from the image in case the module had failed.
One EBS module it's replicated multiple times **within the same region** (remember you can only access an EBS module in the same region).
Your EBS storage can either be SSD or HDD, SSD it's for small blocks and it has high read and write performance. HDD is tuned for bigger blocks (it doesn't have to chunk data into small pieces to store, but just continually writes onto the disk with no interruption)

## Elastic File System
it's a file system, so level abstractions, that you can access concurrently with many user. It is setup at region level, so it can be visible by all the AZs within the same region. When you declare one, AWS automatically creates a mount point that you can use to access the file system.
It's elastic because it can scale indefinitely.

Currently it doesn't support Windows OS, and it's based on NFS 4.0 and 4.1.

You can chose between a standard layer (up to 7000 IOPS) and a max I/O layer which maximise I/O but improves latency.
You are charged by GB/hour you are using in a month.

## Amazon CloudFront
CND - Content Delivery Network
You don't really store data in here, but you use it as a cache to minimize latency when users are trying to access data that you own, let's say in S3.
It's a performance optimisation in order to serve you data faster to users that live in content different from your region.

Cloudfront is located on the so called Edge platform, those are datacenter located close to location densely populated that do not offer the whole set of Amazon services.

It's priced based on the network consumption.

## AWS Storage gateway

It's an abstraction layer that allows the shared file system of your company to be stored into S3 or other AWS Storage Services.
It is an appliance downloaded from Amazon and run as a VM in your data center!

The idea is that you put an AWS Gateway between your company file system and S3 so that you can store and back up your data from your file system
It communicates over the NFS protocol and provide the benfit of quickly represent resources as they were S3 resources.

You can also recover from disasters more quickly because you can build EBS snapshots from data that have been stored in s3 from your file system.

There are different options of usage (?)

Pricing is per: data storage, data transfer and requests.

## AWS Snowball
If you need to transfer data in the order of petabytes and it would take more than a week to upload them using the internt then AWS Snowball might help you. Amazon will send you physical encrypted drives where you'll upload all of your data and ship them back to amazon, which will then upload them to the cloud. Everything is encrypted and support the toughest level of compliance so that even health personal data can be uploaded.

## Test practice

**Question:** In Amazon CloudFront, when using a network of edge locations around the world, requests for your dynamic content are ___________.
**Answer:** sent to your origin servers running within or outside of AWS.
In Amazon CloudFront, requests for your dynamic content are carried back to your origin servers running in Amazon Web Services (e.g., Amazon EC2, Elastic Load Balancing) over optimized network paths for a more reliable and consistent experience. (here)[http://aws.amazon.com/cloudfront/]

 
**Question:** A user has launched a dedicated EBS-backed instance. You are curious where the EBS volume for this instance will be created. 
Which statement is correct about the EBS volume's creation?
**Answer:** The EBS volume will not be created on the same tenant hardware assigned to the dedicated instance.
The dedicated instances are Amazon EC2 instances that run in a Virtual Private Cloud (VPC) on hardware that is dedicated to a single customer. When a user launches an Amazon EBS-backed dedicated instance, the EBS volume does not run on single-tenant hardware. (Here)[http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/dedicated-instance.html]

**Question:** In AWS Storage Gateway, a volume gateway enables you to create volumes and mount them as _____ devices from on-premises application servers.
**Answer:** Internet small computer system interface (iSCSI)
Volume gateway provides an iSCSI target to create volumes and mount them as iSCSI devices from on-premises application servers. The file gateway enables the storage and retrieval of objects in Amazon S3 using file protocols. The tape gateway provides the backup application with an iSCSI virtual tape library (VTL) interface which consists of a virtual media changer, virtual tape drives, and virtual tapes. (here)[http://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html]

**Question:** At what level can Amazon S3 Access Control Lists (ACLs) be applied?
**Answer:** the bucket and object level
S3 ACLs allow identities to access specific objects within buckets a different layered approach than bucket policies which are applied at the bucket level only. ACLs allow you to set certain permissions on each object within a specific Bucket.

These ACLs do not follow that same format as the policies defined by IAM and Bucket policies. Instead, they are far less granular, and different permissions can be applied depending if you are applying an ACL at the bucket or object level. (here)[http://docs.aws.amazon.com/AmazonS3/latest/dev/S3_ACLs_UsingACLs.html]

**Question:** In Amazon Elastic File System (EFS), which of the following performance modes is ideal for applications where tens, hundreds, or thousands of Elastic Compute Cloud (EC2) instances access a file system?
**Answer:** Max I/O mode
Amazon EFS offers two performance modes: General Purpose mode and Max I/O mode. The performance mode is selected when the file system is created. The Max I/O performance mode is best suited for applications where multiple EC2 instances access the file system, as it can scale to higher levels of aggregate throughput and operations per second with a tradeoff of negligibly higher latencies for file operations.
(here)[http://docs.aws.amazon.com/efs/latest/ug/performance.html]


**Question:** What statements regarding EBS encryption are correct? (Choose 2 answers)
**Answer:** 
1. 	EBS automatically encrypts snapshots of encrypted volumes.
2.  EBS automatically encrypts volumes restored from encrypted snapshots.

Snapshots that are taken from encrypted volumes are automatically encrypted. Volumes that are created from encrypted snapshots are also automatically encrypted. Your encrypted volumes and any associated snapshots always remain protected. For more information, see Amazon EBS Encryption. (here)[http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html]
